{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "from sksurv.datasets import load_gbsg2\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('../pysurv/IPD.Mok.A.csv')\n",
    "print(\"The raw_dataset has the following shape: {}.\".format(raw_data.shape))\n",
    "raw_data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an empty chart\n",
    "fig, ((ax1, ax2)) = plt.subplots(1, 2,  figsize=(15, 4))\n",
    "\n",
    "# Counting the number of occurrences for each category \n",
    "data = Counter(raw_data['event'].replace({0:'no event', 1:'event'}))\n",
    "category = list(data.keys())\n",
    "counts = list(data.values())\n",
    "idx = range(len(counts))\n",
    "\n",
    "# Displaying the occurrences of the event/censoring\n",
    "ax1.bar(idx, counts)\n",
    "ax1.set_xticks(idx)\n",
    "ax1.set_xticklabels(category)\n",
    "ax1.set_title( 'Occurences of the event/censoring', fontsize=15)\n",
    "\n",
    "# Showing the histogram of the survival times for the censoring\n",
    "time_0 = raw_data.loc[ raw_data['event'] == 0, 'time']\n",
    "ax2.hist(time_0, bins=30, alpha=0.3, color='blue', label = 'no event')\n",
    "\n",
    "# Showing the histogram of the survival times for the events\n",
    "time_1 = raw_data.loc[ raw_data['event'] == 1, 'time']\n",
    "ax2.hist(time_1, bins=20, alpha=0.7, color='red', label = 'event')\n",
    "ax2.set_title( 'Histogram - survival time', fontsize=15)\n",
    "\n",
    "# Displaying everything side-by-side\n",
    "plt.legend(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating one-hot vectors\n",
    "categories = ['arm']\n",
    "dataset = pd.get_dummies(raw_data, columns=categories, drop_first=True)\n",
    "\n",
    "# Creating the time and event columns\n",
    "time_column = 'time'\n",
    "event_column = 'event'\n",
    "\n",
    "# Extracting the features\n",
    "features = np.setdiff1d(dataset.columns, [time_column, event_column] ).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for null values\n",
    "N_null = sum(dataset[features].isnull().sum())\n",
    "print(\"The raw_dataset contains {} null values\".format(N_null)) #0 null values\n",
    "\n",
    "# Removing duplicates if there exist\n",
    "N_dupli = sum(dataset.duplicated(keep='first'))\n",
    "dataset = dataset.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "print(\"The raw_dataset contains {} duplicates\".format(N_dupli))\n",
    "\n",
    "# Number of samples in the dataset\n",
    "N = dataset.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "index_train, index_test = train_test_split( range(N), test_size = 0.35)\n",
    "data_train = dataset.loc[index_train].reset_index( drop = True )\n",
    "data_test  = dataset.loc[index_test].reset_index( drop = True )\n",
    "\n",
    "# Creating the X, T and E inputs\n",
    "X_train, X_test = data_train[features], data_test[features]\n",
    "T_train, T_test = data_train[time_column], data_test[time_column]\n",
    "E_train, E_test = data_train[event_column], data_test[event_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.models.survival_forest import ConditionalSurvivalForestModel\n",
    "\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# Fitting the model\n",
    "csf = ConditionalSurvivalForestModel(num_trees=1000)\n",
    "csf.fit(X_train, T_train, E_train, max_features='sqrt', max_depth = 5,\n",
    "    min_node_size = 15, num_threads = -1, weights = None,\n",
    "    sample_size_pct = 0.63, importance_mode = 'normalized_permutation',\n",
    "    seed = None, save_memory=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.utils.metrics import concordance_index\n",
    "c_index = concordance_index(csf, X_test, T_test, E_test)\n",
    "print('C-index: {:.2f}'.format(c_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The C-index represents the global assessment of the model discrimination power: this is the modelâ€™s ability to correctly provide a reliable ranking of the survival times based on the individual risk scores. In general, when the C-index is close to 1, the model has an almost perfect discriminatory power; but if it is close to 0.5, it has no ability to discriminate between low and high risk subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.utils.display import integrated_brier_score\n",
    "ibs = integrated_brier_score(csf, X_test, T_test, E_test, t_max=35,\n",
    "    figure_size=(20,5))\n",
    "print('IBS: {:.2f}'.format(ibs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Brier score measures the average discrepancies between the status and the estimated probabilities at a given time. Thus, the lower the score (usually below 0.25), the better the predictive performance. To assess the overall error measure across multiple time points, the Integrated Brier Score (IBS) is usually computed as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.utils.display import compare_to_actual\n",
    "results = compare_to_actual(csf, X_test, T_test, E_test,\n",
    "                            is_at_risk = False,  figure_size=(16, 6),\n",
    "                            metrics = ['rmse', 'mean', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysurvival.utils.display import create_risk_groups\n",
    "\n",
    "risk_groups = create_risk_groups(model=csf, X=X_test,\n",
    "    use_log = False, num_bins=20, figure_size=(10, 4),\n",
    "    experimental={'lower_bound':69, 'upper_bound':75, 'color':'red'},\n",
    "    control={'lower_bound':75, 'upper_bound':82,  'color':'blue'}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the figure\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "# Selecting a random individual that experienced an event from each group\n",
    "groups = []\n",
    "for i, (label, (color, indexes)) in enumerate(risk_groups.items()) :\n",
    "\n",
    "    # Selecting the individuals that belong to this group\n",
    "    if len(indexes) == 0 :\n",
    "        continue\n",
    "    X = X_test.values[indexes, :]\n",
    "    T = T_test.values[indexes]\n",
    "    E = E_test.values[indexes]\n",
    "\n",
    "    # Randomly extracting an individual that experienced an event\n",
    "    choices = np.argwhere((E==1.)).flatten()\n",
    "    if len(choices) == 0 :\n",
    "        continue\n",
    "    k = np.random.choice( choices, 1)[0]\n",
    "\n",
    "    # Saving the time of event\n",
    "    t = T[k]\n",
    "\n",
    "    # Computing the Survival function for all times t\n",
    "    survival = csf.predict_survival(X[k, :]).flatten()\n",
    "\n",
    "    # Displaying the functions\n",
    "    label_ = '{} risk'.format(label)\n",
    "    plt.plot(csf.times, survival, color = color, label=label_, lw=2)\n",
    "    groups.append(label)\n",
    "\n",
    "    # Actual time\n",
    "    plt.axvline(x=t, color=color, ls ='--')\n",
    "    ax.annotate('T={:.1f}'.format(t), xy=(t, 0.5*(1.+0.2*i)),\n",
    "        xytext=(t, 0.5*(1.+0.2*i)), fontsize=12)\n",
    "\n",
    "# Show everything\n",
    "groups_str = ', '.join(groups)\n",
    "title = \"Comparing Survival functions between {} risk grades\".format(groups_str)\n",
    "plt.legend(fontsize=12)\n",
    "plt.title(title, fontsize=15)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
